"""
TWSE è‚¡åƒ¹è³‡æ–™æŠ“å–å·¥å…·
============================

ç¨ç«‹çš„è‚¡åƒ¹æŠ“å–åŠŸèƒ½ï¼Œæ”¯æ´ä¸Šå¸‚ä¸Šæ«ƒè‚¡åƒ¹ä¸‹è¼‰
è¼¸å‡ºæ ¼å¼ï¼šlatest_stock_prices.json å’Œ latest_stock_prices.csv
"""
import os
import sys
import json
from typing import Dict, Any

# åŠ å…¥ç•¶å‰è·¯å¾‘ä»¥ç¢ºä¿æ¨¡çµ„å¯ä»¥æ­£ç¢ºåŒ¯å…¥
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

try:
    # åŒ¯å…¥è¨­å®š
    from config.settings import MERGED_CSV_DIR, MERGED_JSON_DIR, LOG_DIR_BASE, ensure_directories
    
    # åŒ¯å…¥åŠŸèƒ½æ¨¡çµ„
    from utils.logger import Logger
    from downloaders.stock_price_downloader import StockPriceDownloader
    from processors.stock_price_processor import StockPriceProcessor
    
except ImportError as e:
    print(f"âŒ åŒ¯å…¥æ¨¡çµ„å¤±æ•—: {e}")
    print("è«‹ç¢ºèªæ‰€æœ‰å¿…è¦çš„æ¨¡çµ„æª”æ¡ˆéƒ½å­˜åœ¨ä¸”è·¯å¾‘æ­£ç¢º")
    sys.exit(1)


class StockPriceFetcher:
    """è‚¡åƒ¹æŠ“å–ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è‚¡åƒ¹æŠ“å–å™¨"""
        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        ensure_directories()
        
        # è¨­å®šæ—¥èªŒ (æ”¾åœ¨ merged_data æ ¹ç›®éŒ„)
        log_path = os.path.join(LOG_DIR_BASE, "stock_price_log.json")
        self.logger = Logger(log_path)
        
        # åˆå§‹åŒ–ä¸‹è¼‰å™¨å’Œè™•ç†å™¨
        self.downloader = StockPriceDownloader(self.logger)
        self.processor = StockPriceProcessor(self.logger)
        
        # è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        self.json_output_path = os.path.join(MERGED_JSON_DIR, "latest_stock_prices.json")
        self.csv_output_path = os.path.join(MERGED_CSV_DIR, "latest_stock_prices.csv")
    
    def fetch_and_save(self) -> bool:
        """
        æŠ“å–è‚¡åƒ¹è³‡æ–™ä¸¦å„²å­˜
        
        Returns:
            æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        self.logger.info("ğŸš€ é–‹å§‹æŠ“å–æœ€æ–°è‚¡åƒ¹è³‡æ–™...")
        
        try:
            # 1. ä¸‹è¼‰è‚¡åƒ¹è³‡æ–™
            success, raw_data_dict = self.downloader.download_data()
            
            if not success or not raw_data_dict:
                self.logger.error("è‚¡åƒ¹è³‡æ–™ä¸‹è¼‰å¤±æ•—")
                return False
            
            # 2. è™•ç†è³‡æ–™
            processed_df = self.processor.process_stock_data(raw_data_dict)
            
            if processed_df.empty:
                self.logger.error("è‚¡åƒ¹è³‡æ–™è™•ç†å¾Œç‚ºç©º")
                return False
            
            # 3. æ ¼å¼åŒ–è¼¸å‡ºè³‡æ–™
            output_df = self.processor.format_for_output(processed_df)
            
            # 4. å„²å­˜æª”æ¡ˆ
            json_success = self._save_json(output_df)
            csv_success = self._save_csv(output_df)
            
            if json_success and csv_success:
                # 5. è¨˜éŒ„è™•ç†çµæœ
                self._log_result(output_df)
                self.logger.success("ğŸ‰ è‚¡åƒ¹è³‡æ–™æŠ“å–å®Œæˆï¼")
                return True
            else:
                self.logger.error("æª”æ¡ˆå„²å­˜å¤±æ•—")
                return False
                
        except Exception as e:
            self.logger.error(f"è‚¡åƒ¹æŠ“å–éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def _save_json(self, df) -> bool:
        """å„²å­˜ JSON æª”æ¡ˆ"""
        try:
            # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
            data = df.to_dict('records')
            
            # åŠ å…¥å…ƒè³‡æ–™
            output_data = {
                'metadata': self.processor.get_summary_stats(df),
                'data': data
            }
            
            with open(self.json_output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)
            
            self.logger.success(f"JSON å·²å„²å­˜: {self.json_output_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"å„²å­˜ JSON å¤±æ•—: {e}")
            return False
    
    def _save_csv(self, df) -> bool:
        """å„²å­˜ CSV æª”æ¡ˆ"""
        try:
            df.to_csv(self.csv_output_path, index=False, encoding='utf-8-sig')
            self.logger.success(f"CSV å·²å„²å­˜: {self.csv_output_path}")
            return True
            
        except Exception as e:
            self.logger.error(f"å„²å­˜ CSV å¤±æ•—: {e}")
            return False
    
    def _log_result(self, df) -> None:
        """è¨˜éŒ„è™•ç†çµæœ"""
        stats = self.processor.get_summary_stats(df)
        
        log_entry = {
            'type': 'stock_prices',
            'timestamp': stats.get('updated_at'),
            'total_records': stats.get('total_count', 0),
            'tse_records': stats.get('tse_count', 0),
            'otc_records': stats.get('otc_count', 0),
            'price_range': {
                'min': stats.get('price_min', 0),
                'max': stats.get('price_max', 0),
                'mean': stats.get('price_mean', 0)
            },
            'files': {
                'json': self.json_output_path,
                'csv': self.csv_output_path
            }
        }
        
        # å¯«å…¥è™•ç†æ—¥èªŒ
        self.logger.write_processing_log(
            year='current',
            report_name='stock_prices',
            csv_path=self.csv_output_path,
            json_path=self.json_output_path,
            row_count=stats.get('total_count', 0)
        )


def main() -> None:
    """ä¸»ç¨‹å¼å…¥å£"""
    try:
        print("ğŸ¢ TWSE è‚¡åƒ¹è³‡æ–™æŠ“å–å·¥å…·")
        print("=" * 40)
        
        fetcher = StockPriceFetcher()
        success = fetcher.fetch_and_save()
        
        if success:
            print("\nâœ… è‚¡åƒ¹è³‡æ–™æŠ“å–æˆåŠŸï¼")
            print(f"ğŸ“„ JSON æª”æ¡ˆ: {fetcher.json_output_path}")
            print(f"ğŸ“Š CSV æª”æ¡ˆ: {fetcher.csv_output_path}")
        else:
            print("\nâŒ è‚¡åƒ¹è³‡æ–™æŠ“å–å¤±æ•—ï¼")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·ç¨‹å¼åŸ·è¡Œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e}")
        raise


if __name__ == "__main__":
    main()