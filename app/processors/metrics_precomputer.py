"""
é•·è¡¨é è¨ˆç®—ï¼šæ•´åˆ merged_data ä¸­çš„å ±è¡¨æˆçµæ§‹åŒ–é•·è¡¨
å°‡ income_statementã€balance_sheetã€dividend æŒ‰ (code, year, quarter) åˆä½µ
"""
import os
import json
import pandas as pd
import numpy as np
from typing import Dict, List, Any
from datetime import datetime

from config.settings import (
    MERGED_CSV_DIR,
    PRECOMPUTED_METRICS_DIR,
    HISTORICAL_METRICS_FILE,
    METRICS_UPDATE_LOG_FILE,
    SUMMARY_LOG_DIR,
    SUMMARY_PRICE_FILE,
)
from utils.logger import Logger


class MetricsPrecomputer:
    """é è¨ˆç®—é•·è¡¨æŒ‡æ¨™"""

    def __init__(self, logger: Logger = None):
        self.logger = logger or Logger(SUMMARY_LOG_DIR)
        self.merged_csv_dir = MERGED_CSV_DIR
        self.output_dir = PRECOMPUTED_METRICS_DIR
        self.output_file = HISTORICAL_METRICS_FILE
        self.update_log_file = METRICS_UPDATE_LOG_FILE

    def _read_csv_safe(self, path: str) -> pd.DataFrame:
        """å®‰å…¨è®€å– CSVï¼Œè™•ç† BOM å’Œç·¨ç¢¼å•é¡Œ"""
        try:
            df = pd.read_csv(path, dtype=str, encoding="utf-8-sig").replace({"": np.nan})
            df.rename(columns=lambda x: x.strip(), inplace=True)
            # ä¿®æ­£æ¬„ä½åç¨± BOM å•é¡Œ
            if df.columns[0].startswith("\ufeff"):
                df.columns.values[0] = df.columns[0].replace("\ufeff", "")
            return df
        except Exception as e:
            self.logger.error(f"è®€å– {path} å¤±æ•—: {e}")
            return pd.DataFrame()

    def _safe_float(self, val: Any) -> float:
        """å®‰å…¨è½‰æ›ç‚º float"""
        try:
            if pd.isna(val):
                return np.nan
            return float(val)
        except Exception:
            return np.nan

    def _get_all_years(self) -> List[str]:
        """å¾ merged_data ä¸­æå–æ‰€æœ‰å¹´åº¦"""
        years = set()
        for filename in os.listdir(self.merged_csv_dir):
            if filename.endswith("-income_statement.csv"):
                year = filename.split("-")[0]
                years.add(year)
        return sorted(list(years), reverse=True)

    def _load_income_statement(self, years: List[str]) -> pd.DataFrame:
        """è¼‰å…¥æ‰€æœ‰å¹´åº¦çš„ income_statementï¼Œæå– code, year, quarter, eps, profit"""
        dfs = []
        for year in years:
            path = os.path.join(self.merged_csv_dir, f"{year}-income_statement.csv")
            if os.path.exists(path):
                df = self._read_csv_safe(path)
                if df.empty:
                    continue
                # é¸æ“‡éœ€è¦çš„æ¬„ä½
                df = df[["ä»£è™Ÿ", "å¹´åº¦", "å­£åˆ¥", "åŸºæœ¬æ¯è‚¡ç›ˆé¤˜ï¼ˆå…ƒï¼‰", "æ·¨åˆ©"]].copy()
                df.rename(
                    columns={
                        "ä»£è™Ÿ": "code",
                        "å¹´åº¦": "year",
                        "å­£åˆ¥": "quarter",
                        "åŸºæœ¬æ¯è‚¡ç›ˆé¤˜ï¼ˆå…ƒï¼‰": "eps_raw",
                        "æ·¨åˆ©": "profit_raw",
                    },
                    inplace=True,
                )
                # è½‰æ›ç‚º float
                df["eps"] = df["eps_raw"].apply(self._safe_float)
                df["profit"] = df["profit_raw"].apply(self._safe_float)
                dfs.append(df[["code", "year", "quarter", "eps", "profit"]])
        if dfs:
            return pd.concat(dfs, ignore_index=True)
        return pd.DataFrame()

    def _load_balance_sheet(self, years: List[str]) -> pd.DataFrame:
        """è¼‰å…¥æ‰€æœ‰å¹´åº¦çš„ balance_sheetï¼Œæå– code, year, quarter, equity"""
        dfs = []
        for year in years:
            path = os.path.join(self.merged_csv_dir, f"{year}-balance_sheet.csv")
            if os.path.exists(path):
                df = self._read_csv_safe(path)
                if df.empty:
                    continue
                # é¸æ“‡éœ€è¦çš„æ¬„ä½
                df = df[["ä»£è™Ÿ", "å¹´åº¦", "å­£åˆ¥", "æ¬Šç›Šç¸½è¨ˆ"]].copy()
                df.rename(
                    columns={
                        "ä»£è™Ÿ": "code",
                        "å¹´åº¦": "year",
                        "å­£åˆ¥": "quarter",
                        "æ¬Šç›Šç¸½è¨ˆ": "equity_raw",
                    },
                    inplace=True,
                )
                df["equity"] = df["equity_raw"].apply(self._safe_float)
                dfs.append(df[["code", "year", "quarter", "equity"]])
        if dfs:
            return pd.concat(dfs, ignore_index=True)
        return pd.DataFrame()

    def _load_dividend(self, years: List[str]) -> pd.DataFrame:
        """è¼‰å…¥æ‰€æœ‰å¹´åº¦çš„ dividendï¼Œæå– code, year, quarter, cash_dividend"""
        dfs = []
        for year in years:
            path = os.path.join(self.merged_csv_dir, f"{year}-dividend.csv")
            if os.path.exists(path):
                df = self._read_csv_safe(path)
                if df.empty:
                    continue
                # é¸æ“‡éœ€è¦çš„æ¬„ä½
                df = df[["ä»£è™Ÿ", "å¹´åº¦", "å­£åˆ¥", "ç¾é‡‘è‚¡åˆ©"]].copy()
                df.rename(
                    columns={
                        "ä»£è™Ÿ": "code",
                        "å¹´åº¦": "year",
                        "å­£åˆ¥": "quarter",
                        "ç¾é‡‘è‚¡åˆ©": "cash_dividend_raw",
                    },
                    inplace=True,
                )
                df["cash_dividend"] = df["cash_dividend_raw"].apply(self._safe_float)
                # å»é™¤ NaN å’Œ 0 çš„è‚¡åˆ©
                df.loc[df["cash_dividend"] == 0, "cash_dividend"] = np.nan
                dfs.append(df[["code", "year", "quarter", "cash_dividend"]])
        if dfs:
            return pd.concat(dfs, ignore_index=True)
        return pd.DataFrame()

    def _get_valid_stock_codes(self) -> set:
        """å¾ latest_stock_prices.csv ä¸­ç²å–æœ‰æ•ˆçš„è‚¡ç¥¨ä»£è™Ÿ"""
        try:
            price_file = SUMMARY_PRICE_FILE
            if not os.path.exists(price_file):
                self.logger.warning(f"âš ï¸ æ‰¾ä¸åˆ°è‚¡åƒ¹æª”æ¡ˆ: {price_file}ï¼Œå°‡ä½¿ç”¨æ‰€æœ‰è‚¡ç¥¨")
                return set()
            
            df = self._read_csv_safe(price_file)
            if df.empty:
                self.logger.warning("âš ï¸ è‚¡åƒ¹æª”æ¡ˆç‚ºç©ºï¼Œå°‡ä½¿ç”¨æ‰€æœ‰è‚¡ç¥¨")
                return set()
            
            # å–å¾—ä»£è™Ÿæ¬„ä½
            code_col = "stock_code" if "stock_code" in df.columns else "ä»£è™Ÿ"
            if code_col not in df.columns:
                self.logger.warning(f"âš ï¸ æ‰¾ä¸åˆ°ä»£è™Ÿæ¬„ä½ï¼Œå°‡ä½¿ç”¨æ‰€æœ‰è‚¡ç¥¨")
                return set()
            
            valid_codes = set(df[code_col].dropna().unique())
            self.logger.info(f"ğŸ“‹ ç™¼ç¾æœ‰æ•ˆè‚¡ç¥¨: {len(valid_codes)} æ”¯")
            return valid_codes
        except Exception as e:
            self.logger.error(f"âŒ è®€å–è‚¡åƒ¹æª”æ¡ˆå¤±æ•—: {e}ï¼Œå°‡ä½¿ç”¨æ‰€æœ‰è‚¡ç¥¨")
            return set()

    def precompute(self) -> None:
        """åŸ·è¡Œé è¨ˆç®—ï¼šæ•´åˆä¸‰å¼µè¡¨æˆé•·è¡¨"""
        start_time = datetime.now()
        self.logger.info("ğŸš€ é–‹å§‹é è¨ˆç®—é•·è¡¨...")

        try:
            # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
            os.makedirs(self.output_dir, exist_ok=True)

            # ç²å–æ‰€æœ‰å¹´åº¦
            years = self._get_all_years()
            if not years:
                raise ValueError("æœªæ‰¾åˆ°ä»»ä½• income_statement CSV æª”æ¡ˆ")
            self.logger.info(f"ğŸ“Š ç™¼ç¾å¹´åº¦: {', '.join(years)}")

            # è¼‰å…¥ä¸‰å¼µè¡¨
            self.logger.info("ğŸ“¥ è¼‰å…¥ income_statement...")
            eps_df = self._load_income_statement(years)
            self.logger.info(f"   âœ“ å…± {len(eps_df)} ç­† EPS è³‡æ–™")

            self.logger.info("ğŸ“¥ è¼‰å…¥ balance_sheet...")
            equity_df = self._load_balance_sheet(years)
            self.logger.info(f"   âœ“ å…± {len(equity_df)} ç­†æ¬Šç›Šè³‡æ–™")

            self.logger.info("ğŸ“¥ è¼‰å…¥ dividend...")
            dividend_df = self._load_dividend(years)
            self.logger.info(f"   âœ“ å…± {len(dividend_df)} ç­†è‚¡åˆ©è³‡æ–™")

            # åˆä½µä¸‰å¼µè¡¨ï¼šouter join on (code, year, quarter)
            self.logger.info("ğŸ”— åˆä½µä¸‰å¼µè¡¨...")
            result = eps_df.copy()
            result = result.merge(equity_df, on=["code", "year", "quarter"], how="outer")
            result = result.merge(dividend_df, on=["code", "year", "quarter"], how="outer")
            
            # åªä¿ç•™ latest_stock_prices ä¸­æœ‰çš„è‚¡ç¥¨
            valid_codes = self._get_valid_stock_codes()
            if valid_codes:
                result = result[result["code"].isin(valid_codes)]
                self.logger.info(f"   âœ“ éæ¿¾å¾Œ: {len(result)} ç­†è³‡æ–™ï¼ˆ{result['code'].nunique()} æ”¯è‚¡ç¥¨ï¼‰")

            # æ’åºï¼šæŒ‰ code, year (DESC), quarter (DESC)
            result["year_int"] = result["year"].astype(int)
            result["quarter_order"] = result["quarter"].map({"Q1": 1, "Q2": 2, "Q3": 3, "Q4": 4})
            result = result.sort_values(by=["code", "year_int", "quarter_order"], ascending=[True, False, False])
            
            # è¨˜éŒ„å¹´åº¦ç¯„åœï¼ˆåœ¨åˆªé™¤ year_int ä¹‹å‰ï¼‰
            year_min = result["year_int"].min()
            year_max = result["year_int"].max()
            
            # åªä¿ç•™æœ€çµ‚æ¬„ä½
            result = result[["code", "year", "quarter", "eps", "profit", "equity", "cash_dividend"]]

            # ä¿å­˜é•·è¡¨
            self.logger.info(f"ğŸ’¾ ä¿å­˜é•·è¡¨åˆ° {self.output_file}...")
            result.to_csv(self.output_file, index=False, encoding="utf-8-sig")
            self.logger.info(f"   âœ“ å…± {len(result)} ç­†è³‡æ–™")

            # è¨˜éŒ„æ›´æ–°æ™‚é–“
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            log_data = {
                "last_update": end_time.isoformat(),
                "duration_seconds": duration,
                "total_records": len(result),
                "unique_stocks": result["code"].nunique(),
                "year_range": f"{year_min} - {year_max}",
            }
            os.makedirs(os.path.dirname(self.update_log_file), exist_ok=True)
            with open(self.update_log_file, "w", encoding="utf-8") as f:
                json.dump(log_data, f, ensure_ascii=False, indent=2)

            self.logger.info(f"âœ… é è¨ˆç®—å®Œæˆï¼è€—æ™‚ {duration:.2f} ç§’")
            return log_data

        except Exception as e:
            self.logger.error(f"âŒ é è¨ˆç®—å¤±æ•—: {e}")
            raise


def main():
    """ä¸»å…¥å£"""
    logger = Logger(SUMMARY_LOG_DIR)
    precomputer = MetricsPrecomputer(logger)
    precomputer.precompute()


if __name__ == "__main__":
    main()
