"""
TWSE è³‡æ–™ä¸‹è¼‰èˆ‡åˆä½µå·¥å…· - å„ªåŒ–ç‰ˆæœ¬ V2
==============================

ç°¡æ½”çš„ä¸»ç¨‹å¼ï¼Œå°ˆæ³¨æ–¼æµç¨‹å”èª¿
"""
import os
import sys
import shutil
from typing import List

# åŠ å…¥ç•¶å‰è·¯å¾‘ä»¥ç¢ºä¿æ¨¡çµ„å¯ä»¥æ­£ç¢ºåŒ¯å…¥
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

try:
    # åŒ¯å…¥è¨­å®š
    from config.settings import (
        START_YEAR, END_YEAR, ONLY_MERGE, DOWNLOAD_REPORTS, SAVE_FORMAT,
        BASE_DIR, CSV_OUTPUT_DIR, JSON_OUTPUT_DIR, LOG_PATH, ensure_directories
    )

    # åŒ¯å…¥è™•ç†å™¨
    from utils.logger import Logger
    from processors.report_processor import ReportProcessor
    from downloaders.twse_downloader import TWSEDownloader
    from downloaders.etf_downloader import ETFDownloader
    
except ImportError as e:
    print(f"âŒ åŒ¯å…¥æ¨¡çµ„å¤±æ•—: {e}")
    print("è«‹ç¢ºèªæ‰€æœ‰å¿…è¦çš„æ¨¡çµ„æª”æ¡ˆéƒ½å­˜åœ¨ä¸”è·¯å¾‘æ­£ç¢º")
    sys.exit(1)


class TWSEDataProcessor:
    """TWSE è³‡æ–™è™•ç†ä¸»æ§åˆ¶å™¨ - ç°¡æ½”ç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–è™•ç†å™¨"""
        self.logger = Logger(LOG_PATH)
        self.report_processor = ReportProcessor(self.logger)
        self.twse_downloader = TWSEDownloader(self.logger)
        self.etf_downloader = ETFDownloader(self.logger)
        
        ensure_directories()
        
        # æ”¯æ´çš„å ±è¡¨é¡å‹
        self.supported_reports = [
            "balance_sheet", "income_statement", "cash_flow", 
            "dividend", "etf_dividend"
        ]
    
    def process_all_reports(self) -> None:
        """è™•ç†æ‰€æœ‰å ±è¡¨"""
        self.logger.info("ğŸš€ é–‹å§‹è™•ç† TWSE è³‡æ–™...")
        
        reports_to_process = self._get_reports_to_process()
        
        for report_name in reports_to_process:
            self._process_single_report(report_name)
        
        self.logger.success("ğŸ‰ æ‰€æœ‰è™•ç†å®Œæˆï¼")
    
    def _get_reports_to_process(self) -> List[str]:
        """å–å¾—è¦è™•ç†çš„å ±è¡¨æ¸…å–®"""
        if DOWNLOAD_REPORTS and 'all' not in DOWNLOAD_REPORTS:
            return [r for r in DOWNLOAD_REPORTS if r in self.supported_reports]
        else:
            return self.supported_reports.copy()
    
    def _process_single_report(self, report_name: str) -> None:
        """è™•ç†å–®ä¸€å ±è¡¨é¡å‹"""
        self.logger.info(f"\n=== é–‹å§‹è™•ç† {report_name} ===")
        
        for year in range(START_YEAR, END_YEAR + 1):
            year_str = str(year)
            year_dir = os.path.join(BASE_DIR, report_name, year_str)
            
            # 1. ç¢ºä¿è³‡æ–™å¯ç”¨ï¼ˆä¸‹è¼‰æˆ–æª¢æŸ¥ç¾æœ‰è³‡æ–™ï¼‰
            if not self._ensure_data_available(report_name, year_str, year_dir):
                continue
            
            # 2. è™•ç†è³‡æ–™ï¼ˆä½¿ç”¨å°ˆé–€çš„è™•ç†å™¨ï¼‰
            processed_df = self.report_processor.process_year_data(report_name, year_str, year_dir)
            
            if processed_df.empty:
                continue
            
            # 3. å„²å­˜çµæœ
            self._save_processed_data(processed_df, report_name, year_str)
    
    def _ensure_data_available(self, report_name: str, year_str: str, year_dir: str) -> bool:
        """ç¢ºä¿è³‡æ–™å¯ç”¨ï¼ˆä¸‹è¼‰æˆ–æª¢æŸ¥ç¾æœ‰è³‡æ–™ï¼‰"""
        if ONLY_MERGE:
            self.logger.progress(f"åƒ…åˆä½µæ¨¡å¼: è™•ç† {year_str} {report_name}")
            if not os.path.exists(year_dir):
                self.logger.error(f"æ‰¾ä¸åˆ°è³‡æ–™å¤¾: {year_dir}")
                return False
            return True
        else:
            self.logger.progress(f"ä¸‹è¼‰æ¨¡å¼: è™•ç† {year_str} {report_name}")
            return self._download_data(report_name, year_str, year_dir)
    
    def _download_data(self, report_name: str, year_str: str, year_dir: str) -> bool:
        """ä¸‹è¼‰è³‡æ–™"""
        # æ¸…ç†èˆŠè³‡æ–™
        if os.path.exists(year_dir):
            shutil.rmtree(year_dir)
        os.makedirs(year_dir, exist_ok=True)
        
        try:
            if report_name == "etf_dividend":
                return self.etf_downloader.download_data(year_str, year_dir)
            else:
                return self.twse_downloader.download_data(year_str, report_name, year_dir)
        except Exception as e:
            self.logger.error(f"ä¸‹è¼‰ {year_str} {report_name} å¤±æ•—: {e}")
            return False
    
    def _save_processed_data(self, df, report_name: str, year_str: str) -> None:
        """å„²å­˜è™•ç†å¾Œçš„è³‡æ–™"""
        csv_path = json_path = None
        
        # å„²å­˜ CSV
        if "csv" in SAVE_FORMAT:
            csv_path = os.path.join(CSV_OUTPUT_DIR, f"{year_str}-{report_name}.csv")
            df.to_csv(csv_path, index=False, encoding="utf-8-sig")
            self.logger.success(f"CSV å·²å„²å­˜: {csv_path}")
        
        # å„²å­˜ JSON
        if "json" in SAVE_FORMAT:
            json_path = os.path.join(JSON_OUTPUT_DIR, f"{year_str}-{report_name}.json")
            df.to_json(json_path, orient="records", force_ascii=False, indent=2)
            self.logger.success(f"JSON å·²å„²å­˜: {json_path}")
        
        # å¯«å…¥æ—¥èªŒ
        self.logger.write_processing_log(year_str, report_name, csv_path, json_path, len(df))


def main() -> None:
    """ä¸»ç¨‹å¼å…¥å£"""
    try:
        processor = TWSEDataProcessor()
        processor.process_all_reports()
    except KeyboardInterrupt:
        print("\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·ç¨‹å¼åŸ·è¡Œ")
    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e}")
        raise


if __name__ == "__main__":
    main()